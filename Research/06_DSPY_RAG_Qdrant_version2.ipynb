{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532557fa-38a7-4968-bf96-601f918cd5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c78dcf-0c66-408a-8574-c1c651191e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Desktop\\\\Superteams AI\\\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\\\Research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7197c561-854e-43f1-bdfc-e892276cf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561b3278-e4b6-49d3-80fb-99e4269e767d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Desktop\\\\Superteams AI\\\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62d6086-0764-4ed0-8a78-c5819346fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6246115-1370-4365-aa73-04d1fc1793ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c6175f-fd93-492c-834d-27655836c852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>hi. im a home health aide and i have a client ...</td>\n",
       "      <td>hi, thanks for contacting chatbot. swelling in...</td>\n",
       "      <td>137213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>RATIONALE: The COVID-19 pandemic struck an imm...</td>\n",
       "      <td>Hydroxychloroquine vs. Azithromycin for Hospit...</td>\n",
       "      <td>67540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>Objectives: To investigate the experience of p...</td>\n",
       "      <td>Playing the harmonica with chronic obstructive...</td>\n",
       "      <td>109854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, Im sorry to bother you but I have fpund a ...</td>\n",
       "      <td>welcome to chatbot .1. the history suggest a p...</td>\n",
       "      <td>137309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, my penis has  a slightly lighter spot at t...</td>\n",
       "      <td>hello, skin color changes, discoloration etc. ...</td>\n",
       "      <td>135382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  If you are a doctor, please answer the medical...   \n",
       "1     Please summerize the given abstract to a title   \n",
       "2     Please summerize the given abstract to a title   \n",
       "3  If you are a doctor, please answer the medical...   \n",
       "4  If you are a doctor, please answer the medical...   \n",
       "\n",
       "                                               input  \\\n",
       "0  hi. im a home health aide and i have a client ...   \n",
       "1  RATIONALE: The COVID-19 pandemic struck an imm...   \n",
       "2  Objectives: To investigate the experience of p...   \n",
       "3  Hi, Im sorry to bother you but I have fpund a ...   \n",
       "4  Hi, my penis has  a slightly lighter spot at t...   \n",
       "\n",
       "                                              output  __index_level_0__  \n",
       "0  hi, thanks for contacting chatbot. swelling in...             137213  \n",
       "1  Hydroxychloroquine vs. Azithromycin for Hospit...              67540  \n",
       "2  Playing the harmonica with chronic obstructive...             109854  \n",
       "3  welcome to chatbot .1. the history suggest a p...             137309  \n",
       "4  hello, skin color changes, discoloration etc. ...             135382  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Read the Parquet file into a pyarrow Table\n",
    "table = pq.read_table(\"Dataset/train-00000-of-00001-a77e2814210655f1.parquet\")\n",
    "\n",
    "# Convert the Table to a pandas DataFrame\n",
    "df = table.to_pandas()\n",
    "\n",
    "# Now you can work with the DataFrame as usual\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ad14d4b-932a-499a-9fba-2acd921ad5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>hi. im a home health aide and i have a client ...</td>\n",
       "      <td>hi, thanks for contacting chatbot. swelling in...</td>\n",
       "      <td>137213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>RATIONALE: The COVID-19 pandemic struck an imm...</td>\n",
       "      <td>Hydroxychloroquine vs. Azithromycin for Hospit...</td>\n",
       "      <td>67540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>Objectives: To investigate the experience of p...</td>\n",
       "      <td>Playing the harmonica with chronic obstructive...</td>\n",
       "      <td>109854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, Im sorry to bother you but I have fpund a ...</td>\n",
       "      <td>welcome to chatbot .1. the history suggest a p...</td>\n",
       "      <td>137309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, my penis has  a slightly lighter spot at t...</td>\n",
       "      <td>hello, skin color changes, discoloration etc. ...</td>\n",
       "      <td>135382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  If you are a doctor, please answer the medical...   \n",
       "1     Please summerize the given abstract to a title   \n",
       "2     Please summerize the given abstract to a title   \n",
       "3  If you are a doctor, please answer the medical...   \n",
       "4  If you are a doctor, please answer the medical...   \n",
       "\n",
       "                                               input  \\\n",
       "0  hi. im a home health aide and i have a client ...   \n",
       "1  RATIONALE: The COVID-19 pandemic struck an imm...   \n",
       "2  Objectives: To investigate the experience of p...   \n",
       "3  Hi, Im sorry to bother you but I have fpund a ...   \n",
       "4  Hi, my penis has  a slightly lighter spot at t...   \n",
       "\n",
       "                                              output  __index_level_0__  \n",
       "0  hi, thanks for contacting chatbot. swelling in...             137213  \n",
       "1  Hydroxychloroquine vs. Azithromycin for Hospit...              67540  \n",
       "2  Playing the harmonica with chronic obstructive...             109854  \n",
       "3  welcome to chatbot .1. the history suggest a p...             137309  \n",
       "4  hello, skin color changes, discoloration etc. ...             135382  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dfcopy with 100 rows\n",
    "dfcopy = df.head(15).copy()\n",
    "\n",
    "# Display the first few rows\n",
    "dfcopy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "245ca9f8-c74f-4a56-9d23-45c4f1750794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>hi. im a home health aide and i have a client ...</td>\n",
       "      <td>hi, thanks for contacting chatbot. swelling in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>RATIONALE: The COVID-19 pandemic struck an imm...</td>\n",
       "      <td>Hydroxychloroquine vs. Azithromycin for Hospit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>Objectives: To investigate the experience of p...</td>\n",
       "      <td>Playing the harmonica with chronic obstructive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, Im sorry to bother you but I have fpund a ...</td>\n",
       "      <td>welcome to chatbot .1. the history suggest a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, my penis has  a slightly lighter spot at t...</td>\n",
       "      <td>hello, skin color changes, discoloration etc. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  If you are a doctor, please answer the medical...   \n",
       "1     Please summerize the given abstract to a title   \n",
       "2     Please summerize the given abstract to a title   \n",
       "3  If you are a doctor, please answer the medical...   \n",
       "4  If you are a doctor, please answer the medical...   \n",
       "\n",
       "                                               input  \\\n",
       "0  hi. im a home health aide and i have a client ...   \n",
       "1  RATIONALE: The COVID-19 pandemic struck an imm...   \n",
       "2  Objectives: To investigate the experience of p...   \n",
       "3  Hi, Im sorry to bother you but I have fpund a ...   \n",
       "4  Hi, my penis has  a slightly lighter spot at t...   \n",
       "\n",
       "                                              output  \n",
       "0  hi, thanks for contacting chatbot. swelling in...  \n",
       "1  Hydroxychloroquine vs. Azithromycin for Hospit...  \n",
       "2  Playing the harmonica with chronic obstructive...  \n",
       "3  welcome to chatbot .1. the history suggest a p...  \n",
       "4  hello, skin color changes, discoloration etc. ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcopy = dfcopy.drop(\"__index_level_0__\", axis=1)\n",
    "dfcopy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079b49ef-f90f-4edb-9fbc-f07761d332a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'sentence-transformers/all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad0c078-6bad-4f7c-822e-94b26f6bca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# from pathlib import Path\n",
    "\n",
    "# def download_model_and_tokenizer(model_name, save_path):\n",
    "#     \"\"\"\n",
    "#     Download and save both the model and the tokenizer to the specified directory.\n",
    "\n",
    "#     Parameters:\n",
    "#         model_name (str): Name of the model to download.\n",
    "#         save_path (str or Path): Path to the directory where the model and tokenizer will be saved.\n",
    "#     \"\"\"\n",
    "#     # Create the save path if it doesn't exist\n",
    "#     save_path = Path(save_path)\n",
    "#     save_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     # Initialize tokenizer and model\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#     model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "#     # Save tokenizer\n",
    "#     tokenizer.save_pretrained(save_path)\n",
    "    \n",
    "#     # Save model\n",
    "#     model.save_pretrained(save_path)\n",
    "\n",
    "# # Example usage\n",
    "# model_name = 'sentence-transformers/all-MiniLM-L6-v2'  # Model name to download\n",
    "# save_path = Path(\"MiniLM-L6-v2/\")  # Path where model and tokenizer will be saved\n",
    "# download_model_and_tokenizer(model_name, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73b33a7e-3a12-4c12-b93d-f65538a04d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def load_model_and_tokenizer(model_path):\n",
    "    \"\"\"\n",
    "    Load the model and tokenizer from the specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        model_path (str or Path): Path to the directory containing the saved model and tokenizer.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer (transformers.PreTrainedTokenizer): Loaded tokenizer.\n",
    "        model (transformers.PreTrainedModel): Loaded model.\n",
    "    \"\"\"\n",
    "    model_path = Path(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    return tokenizer, model\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_path = Path(\"MiniLM-L6-v2/\")\n",
    "tokenizer, model = load_model_and_tokenizer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a528176e-2868-422e-b29b-45f315b46471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    encoder = EncoderCT2fromHfHub(\n",
    "        model_name_or_path=\"michaelfeil/ct2fast-all-MiniLM-L6-v2\",\n",
    "        device=\"cuda\",\n",
    "        compute_type=\"int8_float16\"\n",
    "    )\n",
    "    # Generate embeddings\n",
    "    embeddings = encoder.generate([text])\n",
    "    # Process embeddings here, e.g., extract pooler_output, convert to list, etc.\n",
    "    # This step depends on the structure of the embeddings returned by your model\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cafb082b-53f7-477d-b1b9-8a7212667584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pooler_output': tensor([[-7.3051e-03,  5.3436e-02,  4.9286e-02,  5.5756e-02, -1.4343e-02,\n",
       "           9.7809e-03, -1.6129e-02,  2.8091e-02,  1.0979e-02,  1.2684e-04,\n",
       "           4.6959e-03,  9.0332e-02,  6.7139e-02,  5.2551e-02, -6.4087e-02,\n",
       "           1.2195e-01,  1.2549e-01, -1.0963e-02, -1.5678e-03,  4.9500e-02,\n",
       "          -1.7120e-02, -1.5045e-02,  8.3740e-02,  3.2562e-02,  1.2398e-02,\n",
       "           6.8481e-02,  9.2087e-03,  1.3657e-02, -4.3854e-02,  8.2458e-02,\n",
       "           8.2764e-02,  5.1910e-02, -1.1688e-01,  6.7932e-02, -1.6174e-02,\n",
       "          -1.4197e-01,  4.5837e-02,  5.0018e-02, -3.7270e-03, -1.5230e-03,\n",
       "           3.8116e-02,  1.4549e-02, -6.0211e-02,  1.5930e-01, -2.3560e-02,\n",
       "           3.7231e-02, -1.7175e-01,  1.6785e-02,  8.1726e-02, -7.0915e-03,\n",
       "          -9.3079e-02,  4.4128e-02,  4.9652e-02,  1.4313e-02, -4.8065e-02,\n",
       "           7.5867e-02,  1.0818e-02, -1.6708e-02,  6.3965e-02,  1.0901e-01,\n",
       "           4.2114e-02, -4.6234e-03, -1.2848e-02,  4.7333e-02, -6.3171e-02,\n",
       "          -2.8595e-02, -4.1077e-02, -8.7891e-02, -5.2979e-02, -3.0624e-02,\n",
       "           2.3132e-02,  4.0253e-02, -6.8909e-02,  2.9572e-02,  3.7415e-02,\n",
       "           8.3130e-02, -8.1116e-02, -4.7150e-02, -7.2021e-02,  6.4453e-02,\n",
       "          -4.9286e-03,  6.8909e-02,  4.6295e-02, -9.2651e-02, -1.0815e-01,\n",
       "          -5.6427e-02,  3.5828e-02,  2.6352e-02, -1.1414e-02,  3.6346e-02,\n",
       "           4.7424e-02,  2.5272e-03, -4.0100e-02,  4.7455e-02,  1.8481e-01,\n",
       "          -3.9093e-02, -2.5589e-02, -5.4718e-02, -1.5808e-01,  1.1909e-02,\n",
       "           2.2217e-02, -6.2447e-03, -1.2703e-02,  2.5864e-02,  5.8594e-02,\n",
       "          -5.9265e-02,  1.1497e-02, -2.4652e-04, -3.0899e-02, -3.1796e-03,\n",
       "           1.2219e-01,  5.0629e-02,  6.5613e-02,  4.0009e-02,  1.3817e-02,\n",
       "           2.6749e-02, -3.4119e-02, -4.0436e-02, -1.6235e-01,  1.7249e-01,\n",
       "           1.1090e-01, -7.5134e-02,  3.3569e-02,  8.2764e-02, -8.7280e-02,\n",
       "          -8.1665e-02,  1.4136e-01, -6.2073e-02, -1.4575e-01, -8.3740e-02,\n",
       "           1.1896e-01, -4.9316e-02,  4.2267e-02, -9.3628e-02, -7.6965e-02,\n",
       "           7.9895e-02, -3.4576e-02,  5.2521e-02,  3.4008e-03,  4.6600e-02,\n",
       "           1.3940e-01, -1.1487e-01,  2.7145e-02, -5.6549e-02,  4.3518e-02,\n",
       "           1.5373e-02, -1.2598e-01, -1.3477e-01,  3.0255e-04, -1.1787e-02,\n",
       "           5.7373e-02,  3.7872e-02, -5.7434e-02,  8.0078e-02, -3.6583e-03,\n",
       "           1.1011e-01, -1.2451e-02, -2.6184e-02, -1.9699e-02, -7.7026e-02,\n",
       "          -7.2144e-02, -1.6113e-02,  3.5828e-02,  1.9882e-02, -4.7638e-02,\n",
       "           4.1656e-02, -4.1595e-02,  6.0883e-02,  8.8959e-03, -2.9724e-02,\n",
       "           2.9861e-02,  3.6652e-02, -6.7078e-02, -9.1980e-02,  2.3056e-02,\n",
       "          -5.5542e-03,  1.3513e-01, -6.9336e-02, -1.4725e-02, -3.5309e-02,\n",
       "           6.1707e-02, -1.0486e-01, -3.2928e-02, -6.9031e-02,  1.8555e-02,\n",
       "           1.4069e-02,  8.0444e-02,  5.9929e-03,  8.8562e-02, -9.3506e-02,\n",
       "          -9.4299e-03,  1.0492e-01,  1.8835e-03,  4.8035e-02, -1.8539e-02,\n",
       "          -3.3661e-02, -6.5063e-02, -3.5217e-02, -8.7204e-03, -5.2582e-02,\n",
       "          -1.1765e-02,  8.0505e-02, -3.6285e-02, -4.2677e-04,  2.9572e-02,\n",
       "           3.2532e-02, -1.1798e-01, -1.1749e-01, -6.0654e-03,  2.1103e-02,\n",
       "           9.5276e-02,  6.6284e-02, -1.1368e-02, -2.0294e-02, -1.2573e-01,\n",
       "          -5.8014e-02,  9.9609e-02,  1.4868e-01,  1.1469e-01, -7.7820e-02,\n",
       "           2.0142e-02, -2.6718e-02, -1.4046e-02, -9.9182e-02, -1.3757e-01,\n",
       "          -6.7902e-03, -5.6854e-02, -1.6589e-01, -2.4200e-02,  3.5828e-02,\n",
       "           1.7242e-02,  2.8549e-02, -2.0416e-02,  1.0376e-01,  7.1259e-03,\n",
       "           6.3660e-02, -2.8641e-02, -4.5166e-03,  1.1072e-01,  1.1719e-02,\n",
       "          -2.0740e-01,  8.7891e-02, -3.7140e-02,  4.2496e-03, -1.1029e-01,\n",
       "           9.0576e-02,  9.2773e-02, -6.3477e-03,  4.3640e-03, -2.5986e-02,\n",
       "           7.0007e-02, -1.7838e-02,  7.5035e-03,  7.8247e-02, -7.7942e-02,\n",
       "          -8.5220e-03,  5.2246e-02, -3.2166e-02,  7.5684e-02,  2.8198e-02,\n",
       "          -8.2764e-02,  1.4214e-02, -1.7822e-02,  1.6373e-02, -1.3440e-01,\n",
       "          -7.6965e-02,  3.6224e-02, -1.0309e-01,  3.2104e-02, -1.1371e-01,\n",
       "           1.1682e-01,  5.6061e-02, -8.0322e-02, -1.0628e-02,  8.1970e-02,\n",
       "           6.2134e-02, -4.1313e-03, -8.9600e-02,  3.9459e-02,  1.8677e-02,\n",
       "           1.4267e-03,  8.2703e-02,  4.4922e-02, -4.2999e-02,  3.8452e-02,\n",
       "           2.2324e-02,  3.5461e-02, -3.8940e-02,  7.4120e-03,  1.3708e-01,\n",
       "           1.8148e-03,  5.3482e-03, -2.4765e-02,  9.8801e-03, -9.8694e-02,\n",
       "          -2.6035e-03,  7.8613e-02,  1.2537e-01,  4.9561e-02,  2.4338e-02,\n",
       "          -6.7139e-03, -4.7333e-02,  1.0291e-01,  1.0500e-03, -3.7628e-02,\n",
       "           3.2196e-02, -7.5195e-02, -1.7181e-02, -3.6743e-02,  8.8577e-03,\n",
       "           1.0071e-01,  6.0181e-02, -2.0203e-02,  9.1003e-02, -7.7087e-02,\n",
       "          -4.1260e-02,  1.0155e-02, -3.3417e-02,  3.7628e-02, -1.7624e-02,\n",
       "           3.1036e-02, -6.7261e-02, -4.2816e-02,  5.9906e-02, -9.4604e-03,\n",
       "           1.9073e-02,  2.4490e-02,  2.7786e-02, -6.0303e-02,  2.8198e-02,\n",
       "           3.0838e-02, -6.4575e-02,  4.1077e-02,  1.3171e-01,  8.4351e-02,\n",
       "          -1.1761e-01,  6.4087e-02,  2.7237e-02,  7.1716e-02, -3.3593e-04,\n",
       "           7.3853e-02, -6.2744e-02, -1.5442e-02, -3.4088e-02,  7.6660e-02,\n",
       "          -1.2018e-01,  1.3590e-03,  4.0009e-02,  3.1494e-02, -2.5578e-03,\n",
       "          -2.4323e-02, -7.3120e-02,  9.9121e-02,  2.6855e-02, -3.5522e-02,\n",
       "          -6.8970e-02, -1.6312e-02, -7.0251e-02,  4.9530e-02, -5.0720e-02,\n",
       "           5.7793e-03, -2.3239e-02, -4.8126e-02, -1.5295e-01,  6.1859e-02,\n",
       "          -5.0842e-02,  1.5686e-02,  1.1237e-01,  1.4490e-01,  1.5326e-03,\n",
       "          -1.4587e-01,  3.3386e-02,  1.0858e-01,  3.1677e-02, -8.3984e-02,\n",
       "          -7.8674e-02, -7.1411e-02,  1.1505e-01, -9.3079e-02, -5.1544e-02,\n",
       "           4.4189e-02,  1.7731e-02, -7.9468e-02, -7.2388e-02]], device='cuda:0',\n",
       "        dtype=torch.float16),\n",
       " 'last_hidden_state': tensor([[[ 7.3608e-02,  3.2349e-01, -2.5513e-01,  ..., -2.0825e-01,\n",
       "           -1.5955e-01, -2.3804e-01],\n",
       "          [ 4.2847e-02,  5.8887e-01, -4.3359e-01,  ..., -3.2446e-01,\n",
       "           -7.8857e-02, -2.1426e+00],\n",
       "          [ 1.0150e-01, -1.3672e-01, -1.0400e-01,  ..., -2.8516e-01,\n",
       "            1.0332e+00, -6.4941e-01],\n",
       "          ...,\n",
       "          [-2.6416e-01,  1.9946e-01,  2.6660e-01,  ..., -6.6162e-02,\n",
       "            9.3323e-02, -2.5586e-01],\n",
       "          [ 8.4839e-03,  9.1370e-02, -3.9087e-01,  ..., -2.4756e-01,\n",
       "            2.5610e-01, -4.1428e-03],\n",
       "          [-1.5421e-03, -8.8654e-03, -3.9551e-01,  ..., -3.1274e-01,\n",
       "            5.1416e-01,  4.1718e-02]]], device='cuda:0', dtype=torch.float16),\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " generate_embedding(\"Azithromycin is an antibiotic that is commonly used to treat bacterial and viral infections in the respiratory system, such as strep throat and pneumonia. It works by inhibiting the growth of certain bacteria and viruses that cause these infections by interfering with their ability to reproduce and replicate their DNA. Additionally, azithromycin has been shown to have antiviral effects against certain viruses, including SARS-CoV-2, the virus that causes COVID-19.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3675b96-3849-48ee-86e7-1cd2100819fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>hi. im a home health aide and i have a client ...</td>\n",
       "      <td>hi, thanks for contacting chatbot. swelling in...</td>\n",
       "      <td>[0.05584716796875, 0.01099395751953125, 0.0569...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>RATIONALE: The COVID-19 pandemic struck an imm...</td>\n",
       "      <td>Hydroxychloroquine vs. Azithromycin for Hospit...</td>\n",
       "      <td>[-0.03765869140625, 0.0582275390625, -0.002435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>Objectives: To investigate the experience of p...</td>\n",
       "      <td>Playing the harmonica with chronic obstructive...</td>\n",
       "      <td>[0.0408935546875, 0.12445068359375, 0.00955963...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, Im sorry to bother you but I have fpund a ...</td>\n",
       "      <td>welcome to chatbot .1. the history suggest a p...</td>\n",
       "      <td>[0.03314208984375, 0.00809478759765625, 0.0678...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, my penis has  a slightly lighter spot at t...</td>\n",
       "      <td>hello, skin color changes, discoloration etc. ...</td>\n",
       "      <td>[-0.004528045654296875, -0.0316162109375, 0.04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  If you are a doctor, please answer the medical...   \n",
       "1     Please summerize the given abstract to a title   \n",
       "2     Please summerize the given abstract to a title   \n",
       "3  If you are a doctor, please answer the medical...   \n",
       "4  If you are a doctor, please answer the medical...   \n",
       "\n",
       "                                               input  \\\n",
       "0  hi. im a home health aide and i have a client ...   \n",
       "1  RATIONALE: The COVID-19 pandemic struck an imm...   \n",
       "2  Objectives: To investigate the experience of p...   \n",
       "3  Hi, Im sorry to bother you but I have fpund a ...   \n",
       "4  Hi, my penis has  a slightly lighter spot at t...   \n",
       "\n",
       "                                              output  \\\n",
       "0  hi, thanks for contacting chatbot. swelling in...   \n",
       "1  Hydroxychloroquine vs. Azithromycin for Hospit...   \n",
       "2  Playing the harmonica with chronic obstructive...   \n",
       "3  welcome to chatbot .1. the history suggest a p...   \n",
       "4  hello, skin color changes, discoloration etc. ...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.05584716796875, 0.01099395751953125, 0.0569...  \n",
       "1  [-0.03765869140625, 0.0582275390625, -0.002435...  \n",
       "2  [0.0408935546875, 0.12445068359375, 0.00955963...  \n",
       "3  [0.03314208984375, 0.00809478759765625, 0.0678...  \n",
       "4  [-0.004528045654296875, -0.0316162109375, 0.04...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hf_hub_ctranslate2 import EncoderCT2fromHfHub\n",
    "import pandas as pd\n",
    "\n",
    "# Function to initialize the encoder and generate embeddings\n",
    "def generate_embeddings(text):\n",
    "    encoder = EncoderCT2fromHfHub(\n",
    "        model_name_or_path=\"michaelfeil/ct2fast-all-MiniLM-L6-v2\",\n",
    "        device=\"cuda\",\n",
    "        compute_type=\"int8_float16\"\n",
    "    )\n",
    "    # Generate embeddings\n",
    "    embeddings = encoder.generate([text])\n",
    "    # Process embeddings here, e.g., extract pooler_output, convert to list, etc.\n",
    "    # This step depends on the structure of the embeddings returned by your model\n",
    "    processed_embeddings = embeddings['pooler_output'].detach().cpu().numpy().flatten().tolist()\n",
    "    return processed_embeddings\n",
    "\n",
    "def apply_embeddings(dataframe, input_column, output_column):\n",
    "    dataframe[output_column] = dataframe[input_column].apply(generate_embeddings)\n",
    "    return dataframe\n",
    "\n",
    "# Usage\n",
    "\n",
    "dfcopy = apply_embeddings(dfcopy, 'output', 'embeddings')\n",
    "dfcopy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5122f228-7d75-45f3-b231-0e47b3ab0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hf_hub_ctranslate2 import EncoderCT2fromHfHub\n",
    "\n",
    "# # Initialize the encoder with the model from Hugging Face Hub\n",
    "# model_name_2 = \"michaelfeil/ct2fast-all-MiniLM-L6-v2\"\n",
    "# encoder = EncoderCT2fromHfHub(\n",
    "#     model_name_or_path=model_name_2, \n",
    "#     device=\"cuda\", \n",
    "#     compute_type=\"int8_float16\"\n",
    "# )\n",
    "\n",
    "# # Encode the text sequences\n",
    "# # Note: The actual method to call and its parameters might differ based on the specific encoder implementation.\n",
    "# # This is a generic way to process input assuming the encoder expects tokenized text.\n",
    "# inputs = [\"I like soccer\", \"I like tennis\", \"The Eiffel Tower is in Paris\"]\n",
    "# encoded_outputs = encoder.generate(inputs)\n",
    "\n",
    "# # Process the encoded outputs\n",
    "# print(encoded_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "494d9f95-919e-4536-ba33-60b5b19ae877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>hi. im a home health aide and i have a client ...</td>\n",
       "      <td>hi, thanks for contacting chatbot. swelling in...</td>\n",
       "      <td>137213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>RATIONALE: The COVID-19 pandemic struck an imm...</td>\n",
       "      <td>Hydroxychloroquine vs. Azithromycin for Hospit...</td>\n",
       "      <td>67540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please summerize the given abstract to a title</td>\n",
       "      <td>Objectives: To investigate the experience of p...</td>\n",
       "      <td>Playing the harmonica with chronic obstructive...</td>\n",
       "      <td>109854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, Im sorry to bother you but I have fpund a ...</td>\n",
       "      <td>welcome to chatbot .1. the history suggest a p...</td>\n",
       "      <td>137309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are a doctor, please answer the medical...</td>\n",
       "      <td>Hi, my penis has  a slightly lighter spot at t...</td>\n",
       "      <td>hello, skin color changes, discoloration etc. ...</td>\n",
       "      <td>135382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  If you are a doctor, please answer the medical...   \n",
       "1     Please summerize the given abstract to a title   \n",
       "2     Please summerize the given abstract to a title   \n",
       "3  If you are a doctor, please answer the medical...   \n",
       "4  If you are a doctor, please answer the medical...   \n",
       "\n",
       "                                               input  \\\n",
       "0  hi. im a home health aide and i have a client ...   \n",
       "1  RATIONALE: The COVID-19 pandemic struck an imm...   \n",
       "2  Objectives: To investigate the experience of p...   \n",
       "3  Hi, Im sorry to bother you but I have fpund a ...   \n",
       "4  Hi, my penis has  a slightly lighter spot at t...   \n",
       "\n",
       "                                              output  __index_level_0__  \n",
       "0  hi, thanks for contacting chatbot. swelling in...             137213  \n",
       "1  Hydroxychloroquine vs. Azithromycin for Hospit...              67540  \n",
       "2  Playing the harmonica with chronic obstructive...             109854  \n",
       "3  welcome to chatbot .1. the history suggest a p...             137309  \n",
       "4  hello, skin color changes, discoloration etc. ...             135382  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7b832-3a3a-428b-8aba-2030d128a8f8",
   "metadata": {},
   "source": [
    "# Qdrant no dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed4eda22-0c62-4ec1-bfe6-2bb77b758e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: DELETE http://localhost:6333/collections/medical_dataset_noembedding \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize Qdrant client\n",
    "qdrant_client = QdrantClient(host='localhost', port=6333)\n",
    "collection_name =  \"medical_dataset_noembedding\" \n",
    "\n",
    "# Specify the vectors' configuration\n",
    "vectors_config = VectorParams(\n",
    "    size=model.config.hidden_size,  # The size of your embeddings\n",
    "    distance=Distance.COSINE  # The distance metric for the vector space\n",
    ")\n",
    "\n",
    "# Create or recreate the collection with the specified configuration\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=vectors_config,\n",
    "    # Optionally, you can specify other parameters for the collection\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a93315ec-0b03-43dd-96cc-110a4a1fcba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/medical_dataset_noembedding/points?wait=true \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Insert data into Qdrant\n",
    "for index, row in dfcopy.iterrows():\n",
    "    # Ensure the embeddings are a flat list of floats\n",
    "    \n",
    "    qdrant_client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[{\n",
    "            \"id\": index,  # Using the dataframe index as the ID\n",
    "            \"vector\": row['embeddings'],\n",
    "            \"payload\": {\n",
    "                # \"instruction\": row['instruction'], \n",
    "                # \"input\": row['input'],\n",
    "                \"output\": row['output']\n",
    "            }\n",
    "        }]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa397439-3cba-4724-a242-f936e47e7280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:qdrant 'medical_dataset_noembedding' collection created\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"qdrant '{collection_name}' collection created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "420077ea-da51-4e20-92f5-53eec12dbf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:QdrantClient initialized: <qdrant_client.qdrant_client.QdrantClient object at 0x000001F0384A1CC0>\n",
      "INFO:__main__:#################################\n",
      "INFO:__main__:Qdrant vector store initialized: <langchain_community.vectorstores.qdrant.Qdrant object at 0x000001F0BA4BBE50>\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "url = \"http://localhost:6333\"  # URL where the Qdrant service is running\n",
    "collection_name =  \"medical_dataset_noembedding\"  # Name of the collection in Qdrant\n",
    "\n",
    "# Initialize the Qdrant client with the specified URL\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    prefer_grpc=False  # Indicates whether to use gRPC for communication\n",
    ")\n",
    "embedding_model ='sentence-transformers/all-MiniLM-L6-v2'\n",
    "client.set_model(embedding_model)\n",
    "\n",
    "logger.info(f\"QdrantClient initialized: {client}\")  # Prints the client information\n",
    "logger.info(f\"#################################\")  # Prints a separator line\n",
    "\n",
    "# Create a Qdrant object with the specified client, embeddings, and collection name\n",
    "# Initialize the Qdrant vector store from langchain\n",
    "db = Qdrant(\n",
    "    client=client,\n",
    "    embeddings=dfcopy['embeddings'].tolist(),  # Use the generated embeddings\n",
    "    collection_name=collection_name\n",
    ")\n",
    "\n",
    "logger.info(f\"Qdrant vector store initialized: {db}\") # Prints the database object information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "608bb320-3762-4712-99bb-2005258b46b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/medical_dataset_noembedding/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:{'score': 0.7775405, 'doc_id': 1, 'content': 'Hydroxychloroquine vs. Azithromycin for Hospitalized Patients with COVID-19 (HAHPS): Results of a Randomized, Active Comparator Trial'}\n",
      "INFO:__main__:{'score': 0.73449993, 'doc_id': 11, 'content': 'hello there... gum infections occur because of various factors... herpes infection being one amongst them.... people with herpes infection have a decreased immunity.... acyclovir given would further compromise the status... that is when the infections set in... apart from the immunity, local factors also play an important role in the gum hygiene... people with oral sexual behavior (multiple partners) tend to have more of these infections.... you require oral prophylaxis with appropriate antibiotics... please use betadine rinses (5ml) 3-4 times daily to prevent further bacterial growth.... consult you dental surgeon for further clinical evaluation and management....'}\n",
      "INFO:__main__:{'score': 0.707796, 'doc_id': 9, 'content': 'This is no advice'}\n",
      "INFO:__main__:{'score': 0.707796, 'doc_id': 13, 'content': 'This is no advice'}\n",
      "INFO:__main__:{'score': 0.69519657, 'doc_id': 10, 'content': 'hi, dairy have gone through your question. i can understand your concern. your triglycerides level is slightly high.  however, your hdl cholesterol level is very low. hdl is a good cholesterol.  it is protective in heart disease. low hdl is an independent risk factor for coronary heart disease. you should take low fat diet with high amount of polyunsaturated fatty acids. repeat your cholesterol level after a month. hope i have answered your question, if you have doubt then i will be happy to answer. thanks for using chatbot. wish you a very good health.'}\n"
     ]
    }
   ],
   "source": [
    "def similarity_search_with_score(query, k=5):\n",
    "    query_embedding = generate_embeddings(query)\n",
    "    search_results = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=k,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    )\n",
    "    return search_results\n",
    "\n",
    "query = \"What is Azithromycin?\"\n",
    "search_results = similarity_search_with_score(query=query, k=5)\n",
    "\n",
    "for result in search_results:\n",
    "    doc_id = result.id\n",
    "    score = result.score\n",
    "    payload = result.payload  # The payload should contain your text or a reference to it.\n",
    "\n",
    "    # Assuming the payload contains a field 'input' where the text is stored\n",
    "    doc_content = payload.get('output', 'No content available')\n",
    "\n",
    "    # Print the similarity score and document content\n",
    "    logger.info({\"score\": score, \"doc_id\": doc_id, \"content\": doc_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f305b61-0953-4900-8cc8-2861289cacd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from Mistral7b_Model/mistral-7b-instruct-v0.1.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    85.94 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  4807.05 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =    62.50 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =    73.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     9.00 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1060\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '17', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "model_path = r\"Mistral7b_Model/mistral-7b-instruct-v0.1.Q5_K_M.gguf\"\n",
    "\n",
    "n_gpu_layers = -1  # Use GPU if possible, rest on CPU\n",
    "n_batch = 512  # Adjust based on GPU VRAM\n",
    "\n",
    "try:\n",
    "    llm = LlamaCpp(\n",
    "        model_path=model_path,  # Only use model_url, not model_path\n",
    "        n_gpu_layers=n_gpu_layers,\n",
    "        n_batch=n_batch,\n",
    "        verbose=True  # Needed for callback manager\n",
    "    )\n",
    "\n",
    "    # Add your code using llm here\n",
    "except Exception as e:\n",
    "    print(f\"Error creating LlamaCpp instance: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eec77fe8-bcfc-4477-a22c-5930fbc489eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     415.78 ms\n",
      "llama_print_timings:      sample time =     129.92 ms /   256 runs   (    0.51 ms per token,  1970.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     415.57 ms /    46 tokens (    9.03 ms per token,   110.69 tokens per second)\n",
      "llama_print_timings:        eval time =    7673.29 ms /   255 runs   (   30.09 ms per token,    33.23 tokens per second)\n",
      "llama_print_timings:       total time =   10088.62 ms /   301 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\n\\n1. The first Super Bowl was in 1967, and Justin Bieber was born on March 1, 2004. Therefore, he has not yet been born when the first Super Bowl took place.\\n\\n2. Since we are looking for an NFL team that won the Super Bowl during his lifetime, let's focus on years after his birth.\\n\\n3. The next Super Bowl after his birth occurred on January 29, 2005 between the St. Louis Rams and the Indianapolis Colts. Unfortunately, neither of these teams have won another Super Bowl since then.\\n\\n4. The next Super Bowl after this one took place on February 5, 2006 between the Seattle Seahawks and the Denver Broncos. Again, none of these teams have won another Super Bowl since then.\\n\\n5. The next Super Bowl took place on February 4, 2007 between the New England Patriots and the New York Giants. The New England Patriots won that game, making it their third consecutive win and fourth overall. They would go on to win another two Super Bowls before Justin Bieber was born in 2\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b3c3ca5-5475-44e1-a749-e8edbc287fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "\n",
    "template = '''[INST]: You are a Medical expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\\n\n",
    "Context: {context}.\\n\n",
    "Question: {question}\\n\n",
    "Answer: '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5ead27ee-47a3-4c04-a5bf-3ef024f08c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "\n",
    "\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "llm_chain = LLMChain(prompt=rag_prompt, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "556de73f-a5da-45a3-8a8f-f5a323260912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search_with_score(query, k=5):\n",
    "    query_embedding = generate_embeddings(query)\n",
    "    search_results = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=k,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    )\n",
    "\n",
    "    # Extract the document content from the payload and include it in the results\n",
    "    results_with_content = []\n",
    "    for result in search_results:\n",
    "        doc_id = result.id\n",
    "        score = result.score\n",
    "        payload = result.payload  # The payload should contain your text or a reference to it.\n",
    "        \n",
    "        # Extract the document content from the payload\n",
    "        doc_content = payload.get('output', 'No content available')\n",
    "\n",
    "        results_with_content.append((score, doc_content))\n",
    "\n",
    "    # Sort the results based on the similarity score in descending order\n",
    "    sorted_results = sorted(results_with_content, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Concatenate the content of the top k results\n",
    "    concatenated_content = ' '.join([content for _, content in sorted_results[:k]])\n",
    "\n",
    "    return concatenated_content\n",
    "\n",
    "# Query for which you want to find similar documents\n",
    "# query = \"What is Azithromycin?\"\n",
    "# concatenated_contents = similarity_search_with_score(query=query, k=2)\n",
    "\n",
    "# # Print the concatenated content of the top documents\n",
    "# print(\"Concatenated content of the top documents:\", concatenated_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d6fcf95e-b36e-4e13-9837-bbda9e6544a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/medical_dataset_noembedding/points/search \"HTTP/1.1 200 OK\"\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]: You are a Medical expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\n",
      "\n",
      "Context: Hydroxychloroquine vs. Azithromycin for Hospitalized Patients with COVID-19 (HAHPS): Results of a Randomized, Active Comparator Trial hello there... gum infections occur because of various factors... herpes infection being one amongst them.... people with herpes infection have a decreased immunity.... acyclovir given would further compromise the status... that is when the infections set in... apart from the immunity, local factors also play an important role in the gum hygiene... people with oral sexual behavior (multiple partners) tend to have more of these infections.... you require oral prophylaxis with appropriate antibiotics... please use betadine rinses (5ml) 3-4 times daily to prevent further bacterial growth.... consult you dental surgeon for further clinical evaluation and management.... This is no advice This is no advice hi, dairy have gone through your question. i can understand your concern. your triglycerides level is slightly high.  however, your hdl cholesterol level is very low. hdl is a good cholesterol.  it is protective in heart disease. low hdl is an independent risk factor for coronary heart disease. you should take low fat diet with high amount of polyunsaturated fatty acids. repeat your cholesterol level after a month. hope i have answered your question, if you have doubt then i will be happy to answer. thanks for using chatbot. wish you a very good health..\n",
      "\n",
      "Question: What is Azithromycin ?\n",
      "\n",
      "Answer: \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     415.78 ms\n",
      "llama_print_timings:      sample time =      62.31 ms /   127 runs   (    0.49 ms per token,  2038.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     272.70 ms /   384 tokens (    0.71 ms per token,  1408.16 tokens per second)\n",
      "llama_print_timings:        eval time =    3659.62 ms /   126 runs   (   29.04 ms per token,    34.43 tokens per second)\n",
      "llama_print_timings:       total time =    4882.47 ms /   510 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Azithromycin is an antibiotic that is commonly used to treat bacterial and viral infections, including pneumonia, sinus infections, and acute bronchitis. It is also used to treat sexually transmitted infections (STIs) such as chlamydia, gonorrhea, and syphilis. In addition, it is sometimes used to treat heart rhythm disorders and inflammatory conditions such as rheumatoid arthritis. It is usually taken orally as a pill or given by injection, and it is generally considered safe\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Azithromycin ?\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\":query,\n",
    "           \"context\": similarity_search_with_score(query,k=5)\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada474c4-ef3f-40f5-889c-8d9f69569ba5",
   "metadata": {},
   "source": [
    "# Dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "54ebc034-17d4-441d-bc37-2640411c074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qdrant_client = QdrantClient(host='localhost', port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "601ca5e2-89a3-4285-be3f-a0659ed17e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.vectorstores import Qdrant\n",
    "\n",
    "# url = \"http://localhost:6333\"  # URL where the Qdrant service is running\n",
    "# collection_name =  \"medical_dataset\"  # Name of the collection in Qdrant\n",
    "\n",
    "# # Initialize the Qdrant client with the specified URL\n",
    "# client = QdrantClient(\n",
    "#     url=url,\n",
    "#     prefer_grpc=False  # Indicates whether to use gRPC for communication\n",
    "# )\n",
    "\n",
    "# logger.info(f\"QdrantClient initialized: {client}\")  # Prints the client information\n",
    "# logger.info(f\"#################################\")  # Prints a separator line\n",
    "\n",
    "# # Create a Qdrant object with the specified client, embeddings, and collection name\n",
    "# # Initialize the Qdrant vector store from langchain\n",
    "# db = Qdrant(\n",
    "#     client=client,\n",
    "#     embeddings=dfcopy['embeddings'].tolist(),  # Use the generated embeddings\n",
    "#     collection_name=collection_name\n",
    "# )\n",
    "\n",
    "# logger.info(f\"Qdrant vector store initialized: {db}\") # Prints the database object information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dfb30f0a-d9a8-4ba8-bc04-7b5fb7062658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.qdrant_rm import QdrantRM\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "\n",
    "url = \"http://localhost:6333\"  # URL where the Qdrant service is running\n",
    "collection_name =  \"medical_dataset\"  # Name of the collection in Qdrant\n",
    "embedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'  # Model name\n",
    "embedding_model_distance = 'Cosine'  # Distance type\n",
    "qdrant_client = QdrantClient(   url=url,\n",
    "                                prefer_grpc=False  # Indicates whether to use gRPC for communication\n",
    "                            )\n",
    "# Now set the model with the correct parameters\n",
    "qdrant_client.set_model(embedding_model_name)\n",
    "\n",
    "qdrant_retriever_model = QdrantRM(collection_name, \n",
    "                                  qdrant_client, \n",
    "                                  k=3)\n",
    "\n",
    "dspy.settings.configure(lm=llm, rm=qdrant_retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "52794345-b8cb-4183-901d-052c35d93c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/medical_dataset/points/search/batch \"HTTP/1.1 400 Bad Request\"\n"
     ]
    },
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Vector params for fast-all-minilm-l6-v2 are not specified in config\"},\"time\":0.000084156}'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnexpectedResponse\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m retrieve \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mRetrieve(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is Azithromycin ?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m topK_passages \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpassages\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretrieve\u001b[38;5;241m.\u001b[39mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passages for question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, passage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(topK_passages):\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\dspy\\retrieve\\retrieve.py:30\u001b[0m, in \u001b[0;36mRetrieve.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\dspy\\retrieve\\retrieve.py:39\u001b[0m, in \u001b[0;36mRetrieve.forward\u001b[1;34m(self, query_or_queries, k)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# print(queries)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# TODO: Consider removing any quote-like markers that surround the query too.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk\n\u001b[1;32m---> 39\u001b[0m passages \u001b[38;5;241m=\u001b[39m \u001b[43mdsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieveEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(passages\u001b[38;5;241m=\u001b[39mpassages)\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\dsp\\primitives\\search.py:57\u001b[0m, in \u001b[0;36mretrieveEnsemble\u001b[1;34m(queries, k, by_prob)\u001b[0m\n\u001b[0;32m     54\u001b[0m queries \u001b[38;5;241m=\u001b[39m [q \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries \u001b[38;5;28;01mif\u001b[39;00m q]\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queries) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m passages \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries:\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\dsp\\primitives\\search.py:12\u001b[0m, in \u001b[0;36mretrieve\u001b[1;34m(query, k, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mrm:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo RM is loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m passages \u001b[38;5;241m=\u001b[39m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mrm(query, k\u001b[38;5;241m=\u001b[39mk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(passages, Iterable):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# it's not an iterable yet; make it one.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# TODO: we should unify the type signatures of dspy.Retriever\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     passages \u001b[38;5;241m=\u001b[39m [passages]\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\dspy\\retrieve\\retrieve.py:30\u001b[0m, in \u001b[0;36mRetrieve.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\dspy\\retrieve\\qdrant_rm.py:73\u001b[0m, in \u001b[0;36mQdrantRM.forward\u001b[1;34m(self, query_or_queries, k)\u001b[0m\n\u001b[0;32m     70\u001b[0m queries \u001b[38;5;241m=\u001b[39m [q \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m queries \u001b[38;5;28;01mif\u001b[39;00m q]  \u001b[38;5;66;03m# Filter empty queries\u001b[39;00m\n\u001b[0;32m     72\u001b[0m k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk\n\u001b[1;32m---> 73\u001b[0m batch_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qdrant_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_qdrant_collection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m passages_scores \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_results:\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\qdrant_client\\qdrant_fastembed.py:394\u001b[0m, in \u001b[0;36mQdrantFastembedMixin.query_batch\u001b[1;34m(self, collection_name, query_texts, query_filter, limit, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m     request \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSearchRequest(\n\u001b[0;32m    381\u001b[0m         vector\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mNamedVector(\n\u001b[0;32m    382\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector_field_name(), vector\u001b[38;5;241m=\u001b[39mvector\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    388\u001b[0m     )\n\u001b[0;32m    390\u001b[0m     requests\u001b[38;5;241m.\u001b[39mappend(request)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scored_points_to_query_responses(response)\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m ]\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\qdrant_client\\qdrant_client.py:231\u001b[0m, in \u001b[0;36mQdrantClient.search_batch\u001b[1;34m(self, collection_name, requests, consistency, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search for points in multiple collections\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    List of search responses\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msearch_batch(\n\u001b[0;32m    232\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    233\u001b[0m     requests\u001b[38;5;241m=\u001b[39mrequests,\n\u001b[0;32m    234\u001b[0m     consistency\u001b[38;5;241m=\u001b[39mconsistency,\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    236\u001b[0m )\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\qdrant_client\\qdrant_remote.py:359\u001b[0m, in \u001b[0;36mQdrantRemote.search_batch\u001b[1;34m(self, collection_name, requests, consistency, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m     requests \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    356\u001b[0m         GrpcToRest\u001b[38;5;241m.\u001b[39mconvert_search_points(r) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, grpc\u001b[38;5;241m.\u001b[39mSearchPoints) \u001b[38;5;28;01melse\u001b[39;00m r\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m requests\n\u001b[0;32m    358\u001b[0m     ]\n\u001b[1;32m--> 359\u001b[0m     http_res: List[List[models\u001b[38;5;241m.\u001b[39mScoredPoint]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_batch_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsistency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsistency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_request_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSearchRequestBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequests\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m http_res\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:1167\u001b[0m, in \u001b[0;36mSyncPointsApi.search_batch_points\u001b[1;34m(self, collection_name, consistency, search_request_batch)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_batch_points\u001b[39m(\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1160\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1161\u001b[0m     consistency: m\u001b[38;5;241m.\u001b[39mReadConsistency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1162\u001b[0m     search_request_batch: m\u001b[38;5;241m.\u001b[39mSearchRequestBatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m m\u001b[38;5;241m.\u001b[39mInlineResponse20016:\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;124;03m    Retrieve by batch the closest points based on vector similarity and given filtering conditions\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_for_search_batch_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsistency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsistency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_request_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_request_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:474\u001b[0m, in \u001b[0;36m_PointsApi._build_for_search_batch_points\u001b[1;34m(self, collection_name, consistency, search_request_batch)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[0;32m    473\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInlineResponse20016\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[38;5;124;43m/points/search/batch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\qdrant_client\\http\\api_client.py:74\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m url \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m url\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpath_params)\n\u001b[0;32m     73\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbuild_request(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Desktop\\Superteams AI\\Task 1 DSPy-MiniLM_12--Qdrant_RAG_with_Prometheus_Grafana\\RAG-Stack-using-DSPy-Qdrant-Mistral-7B\\venv\\lib\\site-packages\\qdrant_client\\http\\api_client.py:97\u001b[0m, in \u001b[0;36mApiClient.send\u001b[1;34m(self, request, type_)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse\u001b[38;5;241m.\u001b[39mfor_response(response)\n",
      "\u001b[1;31mUnexpectedResponse\u001b[0m: Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Vector params for fast-all-minilm-l6-v2 are not specified in config\"},\"time\":0.000084156}'"
     ]
    }
   ],
   "source": [
    "retrieve = dspy.Retrieve(k=3)\n",
    "question = \"What is Azithromycin ?\"\n",
    "topK_passages = retrieve(question).passages\n",
    "\n",
    "print(f\"Top {retrieve.k} passages for question: {question} \\n\", \"\\n\")\n",
    "\n",
    "for idx, passage in enumerate(topK_passages):\n",
    "    print(f\"{idx+1}]\", passage, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e32f6-c22c-4fc6-8270-c7ba9ef6f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.qdrant_rm import QdrantRM\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# URL where the Qdrant service is running\n",
    "url = \"http://localhost:6333\"\n",
    "\n",
    "# Name of the collection in Qdrant\n",
    "collection_name = \"medical_dataset\"\n",
    "\n",
    "# Model name and the distance type used for embeddings\n",
    "embedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embedding_model_distance = 'Cosine'\n",
    "\n",
    "# Initialize the Qdrant client\n",
    "qdrant_client = QdrantClient(url=url, prefer_grpc=False)\n",
    "\n",
    "# Set the model in the Qdrant client. Ensure this model is properly configured in your Qdrant server.\n",
    "qdrant_client.set_model(embedding_model_name)\n",
    "\n",
    "# Initialize the Qdrant Retriever Model\n",
    "qdrant_retriever_model = QdrantRM(collection_name, qdrant_client, k=3)\n",
    "\n",
    "# Configure dspy to use the initialized retriever model\n",
    "dspy.settings.configure(rm=qdrant_retriever_model)\n",
    "\n",
    "# Setup the Retrieve function with the desired number of top-k passages to retrieve\n",
    "retrieve = dspy.Retrieve(k=3)\n",
    "\n",
    "# Define your question\n",
    "question = \"What is Azithromycin?\"\n",
    "\n",
    "# Retrieve the top-K passages for the given question\n",
    "topK_passages = retrieve(question).passages\n",
    "\n",
    "# Print the top K passages\n",
    "print(f\"Top {retrieve.k} passages for the question: '{question}'\\n\")\n",
    "for idx, passage in enumerate(topK_passages):\n",
    "    print(f\"{idx + 1}]\", passage, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136f4b3-b035-4cae-bcd1-c71a51fdb5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
